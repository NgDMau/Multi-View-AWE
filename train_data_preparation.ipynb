{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_features(audio_path, start_time, end_time, sr=None):\n",
    "    \"\"\"\n",
    "    Extract 39 MFCC features (13 MFCCs + 13 Delta + 13 Delta-Delta) from a specific segment of an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_path: Path to the audio file.\n",
    "    - start_time: Start time of the word segment in seconds.\n",
    "    - end_time: End time of the word segment in seconds.\n",
    "    - sr: Sample rate to use. If None, librosa's default will be used.\n",
    "    \n",
    "    Returns:\n",
    "    - mfcc_features: A numpy array containing 39 MFCC features for the segment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    # Extract the segment\n",
    "    start_sample = int(start_time * sr)\n",
    "    end_sample = int(end_time * sr)\n",
    "    word_segment = y[start_sample:end_sample]\n",
    "    \n",
    "    # Compute 13 MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=word_segment, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Compute Delta and Delta-Delta features\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    # Concatenate to get 39 features\n",
    "    mfcc_features = np.concatenate((mfccs, mfcc_delta, mfcc_delta2), axis=0)\n",
    "    \n",
    "    return mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "audio_path = '/home/ldap-users/Share/Data/librispeech/train-clean-100/19/198/19-198-0000.flac'\n",
    "start_time = 1.0  # Start time of the word in seconds\n",
    "end_time = 1.3    # End time of the word in seconds\n",
    "\n",
    "mfcc_features = extract_mfcc_features(audio_path, start_time, end_time)\n",
    "print(\"MFCC Features Shape:\", mfcc_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# librosa.display.specshow for MFCC (Choose what to display: mfccs, mfcc_delta, mfcc_delta2, or mfcc_combined)\n",
    "librosa.display.specshow(mfcc_features, x_axis='time', sr=16000, cmap='viridis')\n",
    "\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_mfcc_features(audio_path, start_time, end_time, sr=None):\n",
    "    \"\"\"\n",
    "    Extract 39 MFCC features (13 MFCCs + 13 Delta + 13 Delta-Delta) from a specific segment of an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_path: Path to the audio file.\n",
    "    - start_time: Start time of the word segment in seconds.\n",
    "    - end_time: End time of the word segment in seconds.\n",
    "    - sr: Sample rate to use. If None, librosa's default will be used.\n",
    "    \n",
    "    Returns:\n",
    "    - mfcc_features: A numpy array containing 39 MFCC features for the segment.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    # Extract the segment\n",
    "    start_sample = int(start_time * sr)\n",
    "    end_sample = int(end_time * sr)\n",
    "    word_segment = y[start_sample:end_sample]\n",
    "    \n",
    "    # Compute 13 MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=word_segment, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Compute Delta and Delta-Delta features\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    # Concatenate to get 39 features\n",
    "    mfcc_features = np.concatenate((mfccs, mfcc_delta, mfcc_delta2), axis=0)\n",
    "    \n",
    "    return mfcc_features\n",
    "\n",
    "# Load the updated_processed_data.json file\n",
    "with open('Temp_data/new_updated_processed_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "items_to_remove = []\n",
    "items_processed = 0\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "# Process each word and its audio segments\n",
    "for word, sub_json in data.items():\n",
    "    for audio_path, intervals in sub_json.items():\n",
    "        # print(f\"Audio path: {audio_path}\")\n",
    "        # print(f\"Intervals: {intervals}\")\n",
    "        remove_sub_json = False\n",
    "        # Process each interval\n",
    "        for i, interval in enumerate(intervals): \n",
    "            if isinstance(interval, list):\n",
    "                start_time, end_time = interval\n",
    "                if end_time - start_time >= 0.5:\n",
    "                    # print(f\"Start: {start_time}, End: {end_time}\")\n",
    "                    # Extract the MFCC features for this segment\n",
    "                    mfcc_features = extract_mfcc_features(audio_path, start_time, end_time)\n",
    "                    mfcc_features_list = mfcc_features.tolist() if mfcc_features is not None else None\n",
    "                    # Replace the interval with the extracted MFCC features\n",
    "                    print(type(mfcc_features))\n",
    "                    output_data[word] = mfcc_features_list\n",
    "                    print(type(output_data))\n",
    "                    items_processed += 1\n",
    "                    print(f\"Processed: {(items_processed)}\")\n",
    "                    break\n",
    "                else: \n",
    "                    remove_sub_json = True\n",
    "                    break\n",
    "\n",
    "        if remove_sub_json:\n",
    "            items_to_remove.append((word, audio_path))\n",
    "\n",
    "    if items_processed == 10:\n",
    "        break\n",
    "\n",
    "# Remove the marked items from data\n",
    "for word, audio_path in items_to_remove:\n",
    "    # Check if word is still in data and has the specific audio_path, then remove it\n",
    "    if word in data and audio_path in data[word]:\n",
    "        del data[word][audio_path]\n",
    "        # If this was the last audio_path for the word, remove the word entry as well\n",
    "        if data[word]:  # Check if sub_json is empty\n",
    "            del data[word]\n",
    "\n",
    "# Save the updated data back to a new JSON file\n",
    "with open('Temp_data/mfcc_processed_data.json', 'w') as file:\n",
    "    json.dump(output_data, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This part is for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = \"/home/ldap-users/s2210403\"\n",
    "sys.path.append(f'{parent_dir}/VG-HuBERT')\n",
    "\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import os\n",
    "import pickle\n",
    "from models import audio_encoder\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "model_path = \"/home/ldap-users/s2210403/VG-HuBERT/vg-hubert_3\"\n",
    "wav_file = \"/home/ldap-users/Share/Data/librispeech/train-clean-100/19/198/19-198-0037.flac\"\n",
    "tgt_layer = 9\n",
    "threshold = 0.7\n",
    "\n",
    "# setup model\n",
    "with open(os.path.join(model_path, \"args.pkl\"), \"rb\") as f:\n",
    "    model_args = pickle.load(f)\n",
    "model = audio_encoder.AudioEncoder(model_args)\n",
    "bundle = torch.load(os.path.join(model_path, \"best_bundle.pth\"))\n",
    "model.carefully_load_state_dict(bundle['dual_encoder'], load_all=True)\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "\n",
    "def get_segmented(audio_file):\n",
    "    # load waveform (do not layer normalize the waveform!)\n",
    "    audio, sr = sf.read(audio_file, dtype = 'float32')\n",
    "    assert sr == 16000\n",
    "    audio_len_in_sec = len(audio) / sr\n",
    "    audio = torch.from_numpy(audio).unsqueeze(0).cuda() # [T] -> [1, T]\n",
    "\n",
    "    # model forward\n",
    "    with torch.no_grad():\n",
    "        model_out = model(audio, padding_mask=None, mask=False, need_attention_weights=True, tgt_layer=tgt_layer)\n",
    "    feats = model_out['features'].squeeze(0)[1:] # [1, T+1, D] -> [T, D]\n",
    "    spf = audio.shape[-1]/sr/feats.shape[-2]\n",
    "    attn_weights = model_out['attn_weights'].squeeze(0) # [1, num_heads, T+1, T+1] -> [num_heads, T+1, T+1] (for the two T+1, first is target length then the source)\n",
    "    cls_attn_weights = attn_weights[:, 0, 1:] # [num_heads, T+1, T+1] -> [num_heads, T]\n",
    "    out = cls_attn_seg(cls_attn_weights, threshold, spf, audio_len_in_sec) # out contains attn boundaries and word boundaries in intervals\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed data JSON file\n",
    "with open('updated_processed_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "success = 0\n",
    "\n",
    "# Process each word and its sub-jsons\n",
    "for word, sub_json in data.items():\n",
    "    for audio_key, value_indices in sub_json.items():\n",
    "        # Call the get_segmented function with the audio path\n",
    "        result = get_segmented(audio_key)\n",
    "        segmented_list = result[\"attn_boundary_intervals\"]\n",
    "        # Ensure the list has enough elements\n",
    "        if not segmented_list or max(value_indices) >= len(segmented_list):\n",
    "            print(f\"Error: The list returned by get_segmented for {audio_key} does not have an index {value_indices}.Length is {len(segmented_list)}\")\n",
    "            # continue\n",
    "        # Replace the value of the sub-json with the value-th element from the list\n",
    "        # If the value is a list of indices, this will take all corresponding elements.\n",
    "        else:\n",
    "            success += 1\n",
    "            new_values = [segmented_list[index] for index in value_indices]\n",
    "            sub_json[audio_key] = new_values\n",
    "            print(f\"Success: {success}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(out[\"attn_boundary_intervals\"]), \"   \", out[\"attn_boundary_intervals\"])\n",
    "print(len(out[\"word_boundary_intervals\"]), \"   \", out[\"word_boundary_intervals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assume 'base_dir' is the base directory where the audio files are located\n",
    "base_dir = '/home/ldap-users/Share/Data/librispeech/train-clean-100'\n",
    "\n",
    "# Read the processed data JSON file\n",
    "with open('processed_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Update the audio file paths\n",
    "for word, sub_json in data.items():\n",
    "    new_sub_json = {}\n",
    "    for audio_key, transcript_index in sub_json.items():\n",
    "        relative_audio_key = audio_key.replace(base_dir, '')\n",
    "        relative_audio_key = relative_audio_key.split(\"/\")[-1]\n",
    "        # Extract the parts of the audio file name\n",
    "        parts = relative_audio_key.split('-')\n",
    "        if len(parts) == 3:\n",
    "            first_part, second_part, third_part = parts\n",
    "            # Construct the new path\n",
    "            new_audio_path = f\"{base_dir}/{first_part}/{second_part}/{relative_audio_key}\"\n",
    "            new_sub_json[new_audio_path] = transcript_index\n",
    "        else:\n",
    "            print(f\"Unexpected audio key format: {audio_key}\")\n",
    "    # Update the data dictionary with new sub-json\n",
    "    data[word] = new_sub_json\n",
    "\n",
    "# Write the updated data back to a new JSON file\n",
    "with open('updated_processed_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "parent_dir = '/home/ldap-users/Share/Data/librispeech/train-clean-100'\n",
    "json_file = '/home/ldap-users/s2210403/Multi-View-AWE/buckeye_words_found_in_libri100_with_sentences.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(json_file, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the JSON data\n",
    "new_data = {}\n",
    "for word, sub_json in data.items():\n",
    "    new_sub_json = {}\n",
    "    for audio_key, transcript in sub_json.items():\n",
    "        # Split the audio_key into its parts\n",
    "        first_part, second_part, third_part = audio_key.split('-')\n",
    "        # Construct the new key with the full path\n",
    "        new_key = f\"{parent_dir}/{first_part}/{second_part}/{third_part}/{audio_key}.flac\"\n",
    "        # Find the index of the word in the transcript\n",
    "        transcript_words = transcript.split()\n",
    "        word_indices = [index for index, w in enumerate(transcript_words) if w.upper() == word.upper()]\n",
    "        # Update the sub-json with the new key and the word index\n",
    "        new_sub_json[new_key] = word_indices\n",
    "    # Update the new data dictionary\n",
    "    new_data[word] = new_sub_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the processed data back to a new JSON file\n",
    "with open('processed_data.json', 'w') as file:\n",
    "    json.dump(new_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Temp_data/mfcc_processed_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "mfcc_arrays = {word: np.array(features) for word, features in data.items()}\n",
    "\n",
    "np.savez('Temp_data/mfcc_features.npz', **mfcc_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "npz_file = np.load('Temp_data/mfcc_features.npz')\n",
    "\n",
    "# Iterate over items and print\n",
    "for word, features in npz_file.items():\n",
    "    print(f\"Word: {word}\")\n",
    "    print(\"Features:\", features)\n",
    "    # If you only want to print the shape or a summary, you can replace the above line with:\n",
    "    # print(\"Shape of features:\", features.shape)\n",
    "\n",
    "# Close the file after use to free resources\n",
    "npz_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def word_to_char_embeddings(word):\n",
    "    # Filter out non-English letters and convert to lowercase\n",
    "    filtered_word = ''.join(filter(str.isalpha, word)).lower()\n",
    "    # Initialize the embedding matrix with zeros\n",
    "    embedding = np.zeros((len(filtered_word), 26), dtype=np.int8)\n",
    "    for i, char in enumerate(filtered_word):\n",
    "        if char.isalpha():\n",
    "            # Subtract 97 to get 0-based index since 'a' is 97 in ASCII\n",
    "            embedding[i, ord(char) - 97] = 1\n",
    "    return embedding\n",
    "\n",
    "# Load the .npz file\n",
    "npz_file = np.load('Temp_data/mfcc_features.npz')\n",
    "\n",
    "# Initialize lists to hold the MFCC features and character embeddings\n",
    "mfcc_features_list = []\n",
    "char_embeddings_list = []\n",
    "\n",
    "# Iterate over items in the .npz file\n",
    "for word, features in npz_file.items():\n",
    "    # print((features.shape))\n",
    "    mfcc_features_list.append(features)\n",
    "    char_embedding = word_to_char_embeddings(word)\n",
    "    char_embeddings_list.append(char_embedding)\n",
    "\n",
    "max_length = max(features.shape[1] for features in mfcc_features_list)\n",
    "padded_mfcc_features_list = [np.pad(features, ((0, 0), (0, max_length - features.shape[1])), mode='constant', constant_values=0) for features in mfcc_features_list]\n",
    "\n",
    "\n",
    "# Close the .npz file\n",
    "npz_file.close()\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "# mfcc_features_array = np.array(mfcc_features_list, dtype=object)\n",
    "mfcc_features_array = np.array(padded_mfcc_features_list, dtype=object)\n",
    "char_embeddings_array = np.array(char_embeddings_list, dtype=object)\n",
    "\n",
    "# Save the arrays to .npy files\n",
    "np.save('input1.npy', mfcc_features_array)\n",
    "np.save('input2.npy', char_embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n",
      "(39, 37)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "npz_file = np.load('Data/test.npz')\n",
    "\n",
    "# Determine the maximum width among all MFCC feature arrays\n",
    "max_width = max(features.shape[1] for features in npz_file.values())\n",
    "\n",
    "# Initialize a dictionary to hold the padded MFCC features\n",
    "padded_mfcc_features = {}\n",
    "\n",
    "# Iterate over items in the .npz file and pad each MFCC feature array\n",
    "for word, features in npz_file.items():\n",
    "    # Calculate the padding width for the current array\n",
    "    # padding_width = max_width - features.shape[1]\n",
    "    # # Pad the array on the right (along the second axis)\n",
    "    # padded_features = np.pad(features, pad_width=((0, 0), (0, padding_width)), mode='constant', constant_values=0)\n",
    "    # # Store the padded features in the dictionary\n",
    "    # padded_mfcc_features[word] = padded_features\n",
    "    print(features.shape)\n",
    "\n",
    "# Optionally, save the padded MFCC feature arrays to a new .npz file\n",
    "# np.savez('padded_mfcc_features.npz', **padded_mfcc_features)\n",
    "# # Remember to close the loaded .npz file\n",
    "# npz_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiview_awe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
